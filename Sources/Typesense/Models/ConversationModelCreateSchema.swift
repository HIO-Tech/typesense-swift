//
// ConversationModelCreateSchema.swift
//
// Generated by swagger-codegen
// https://github.com/swagger-api/swagger-codegen
//

import Foundation



public struct ConversationModelCreateSchema: Codable {

    /** An explicit id for the model, otherwise the API will return a response with an auto-generated conversation model id. */
    public var _id: String?
    /** Name of the LLM model offered by OpenAI, Cloudflare or vLLM */
    public var modelName: String
    /** The LLM service&#x27;s API Key */
    public var apiKey: String?
    /** Typesense collection that stores the historical conversations */
    public var historyCollection: String?
    /** LLM service&#x27;s account ID (only applicable for Cloudflare) */
    public var accountId: String?
    /** The system prompt that contains special instructions to the LLM */
    public var systemPrompt: String?
    /** Time interval in seconds after which the messages would be deleted. Default: 86400 (24 hours)  */
    public var ttl: Int?
    /** The maximum number of bytes to send to the LLM in every API call. Consult the LLM&#x27;s documentation on the number of bytes supported in the context window.  */
    public var maxBytes: Int
    /** URL of vLLM service */
    public var vllmUrl: String?

    public init(_id: String? = nil, modelName: String, apiKey: String? = nil, historyCollection: String? = nil, accountId: String? = nil, systemPrompt: String? = nil, ttl: Int? = nil, maxBytes: Int, vllmUrl: String? = nil) {
        self._id = _id
        self.modelName = modelName
        self.apiKey = apiKey
        self.historyCollection = historyCollection
        self.accountId = accountId
        self.systemPrompt = systemPrompt
        self.ttl = ttl
        self.maxBytes = maxBytes
        self.vllmUrl = vllmUrl
    }

    public enum CodingKeys: String, CodingKey { 
        case _id = "id"
        case modelName = "model_name"
        case apiKey = "api_key"
        case historyCollection = "history_collection"
        case accountId = "account_id"
        case systemPrompt = "system_prompt"
        case ttl
        case maxBytes = "max_bytes"
        case vllmUrl = "vllm_url"
    }

}
